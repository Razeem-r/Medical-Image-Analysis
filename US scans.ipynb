{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "from math import log10, sqrt\n",
    "path = ('./data_assignment2')\n",
    "filename = [f for f in listdir(path) if isfile(join(path,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only scans\n",
    "x = []\n",
    "for f in filename:\n",
    "    if len(f)==10 :\n",
    "        p=path+'/'+f\n",
    "        x.append(cv2.imread(p))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scans \n",
    "for i in range(len(x)):\n",
    "    cv2.imshow('show',x[i])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "i=0\n",
    "\n",
    "# Iterate and plot \n",
    "while True:\n",
    "    i+=1\n",
    "    plt.subplot(5, 2, i)\n",
    "    img = x[int(i/2)]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 2, i)\n",
    "    h = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    plt.plot(h,color='b')\n",
    "    \n",
    "    if i+1>10:\n",
    "        break\n",
    "    \n",
    "plt.tight_layout()    \n",
    "# plt.savefig('images+hists.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appears Scan 4 has most noise \n",
    "img = x[3]\n",
    "# plt.imshow(img, cmap='gray')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "h = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "plt.plot(h,color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prominently Gaussian and Speckle Noise\n",
    "#PSNR for future calculation\n",
    "def PSNR(original, compressed): \n",
    "    mse = np.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added noise and filtering with Median, Gaussian and Bilateral\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "i=0\n",
    "clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8,8))\n",
    "\n",
    "#Iterate and plot random images\n",
    "while True:\n",
    "#     i+=1\n",
    "#     plt.subplot(5, 4, i)\n",
    "    img = x[int(i/5)]\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "    m = cv2.medianBlur(img,3)\n",
    "    m = cv2.cvtColor(m,cv2.COLOR_BGR2GRAY)\n",
    "    g = cv2.GaussianBlur(img,(3,3),0,0)\n",
    "    g = cv2.cvtColor(g,cv2.COLOR_BGR2GRAY)\n",
    "    b = cv2.bilateralFilter(img,10, 110, 110, cv2.BORDER_DEFAULT)\n",
    "    b = cv2.cvtColor(b,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    h = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    mhi = cv2.calcHist([m],[0],None,[256],[0,256])\n",
    "    plt.imshow(m, cmap='gray')\n",
    "    plt.axis('off') \n",
    "    plt.title('Median Filter')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    ghi = cv2.calcHist([g],[0],None,[256],[0,256])\n",
    "    plt.imshow(g, cmap='gray')\n",
    "    plt.axis('off') \n",
    "    plt.title('Gaussian Filter')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    bhi = cv2.calcHist([b],[0],None,[256],[0,256])\n",
    "    plt.imshow(b, cmap='gray')\n",
    "    plt.axis('off') \n",
    "    plt.title('Bilateral Filter')\n",
    "    \n",
    "    j=i/4\n",
    "    print(f'PSNR of median filtered {j}th scan is {100-PSNR(m,img) : 4f}')\n",
    "    print(f'PSNR of gaussian filtered {j}th scan is {100-PSNR(g,img): 4f}')\n",
    "    print(f'PSNR of bilateral filtered {j}th scan is {100-PSNR(b,img) : 4f}')\n",
    "    if i+1>20:\n",
    "        break\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('images+hists+filtered.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Contrast enhancement / Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying CLAHE on Bilateral filtered scans\n",
    "enh=[]\n",
    "plt.figure(figsize=(30,20))\n",
    "i=0\n",
    "clahe = cv2.createCLAHE(clipLimit=10, tileGridSize=(8,8))\n",
    "\n",
    "#Iterate and plot random images\n",
    "while True:\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    img = x[int(i/5)]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "#     cv2.imwrite('original '+str((i)/5)+'.jpg',img)\n",
    "#     g = cv2.GaussianBlur(img,(3,3),0,0)\n",
    "#     g = cv2.cvtColor(g,cv2.COLOR_BGR2GRAY)\n",
    "    b = cv2.bilateralFilter(img,10, 110, 110, cv2.BORDER_DEFAULT)\n",
    "    b = cv2.cvtColor(b,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     i+=1\n",
    "#     plt.subplot(5, 4, i)\n",
    "#     ghi = cv2.calcHist([g],[0],None,[256],[0,256])\n",
    "#     plt.plot(ghi)\n",
    "#     plt.title('gauss')\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    bhi = cv2.calcHist([b],[0],None,[256],[0,256])\n",
    "    plt.plot(bhi)\n",
    "    plt.title('bilateral')\n",
    "    \n",
    "    i+=1\n",
    "    a = clahe.apply(b)\n",
    "    enh.append(a)\n",
    "#     cv2.imwrite('contrast enhanced '+str((i-2)/5)+'.jpg',a)\n",
    "\n",
    "    plt.subplot(5, 4, i)\n",
    "    clahe1 = cv2.calcHist([a],[0],None,[256],[0,256])\n",
    "    plt.plot(clahe1)\n",
    "    plt.title('clahe_on_bilateral')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "     \n",
    "    if i+1>20:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images+contrast_enhanced.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not bad but lets try Top-hat transform to enhance contrast as well https://en.wikipedia.org/wiki/Top-hat_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enh1=[]\n",
    "plt.figure(figsize=(30,20))\n",
    "i=0\n",
    "filterSize =(30, 30) \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,filterSize) \n",
    "  \n",
    "while True:\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    img = x[int(i/4)]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "#     cv2.imwrite('original '+str((i)/5)+'.jpg',img)\n",
    "#     g = cv2.GaussianBlur(img,(3,3),0,0)\n",
    "#     g = cv2.cvtColor(g,cv2.COLOR_BGR2GRAY)\n",
    "    b = cv2.bilateralFilter(img,10, 70, 70, cv2.BORDER_DEFAULT)\n",
    "    b = cv2.cvtColor(b,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     i+=1\n",
    "#     plt.subplot(5, 4, i)\n",
    "#     ghi = cv2.calcHist([g],[0],None,[256],[0,256])\n",
    "#     plt.plot(ghi)\n",
    "#     plt.title('gauss')\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    bhi = cv2.calcHist([b],[0],None,[256],[0,256])\n",
    "    plt.plot(bhi)\n",
    "    plt.title('bilateral')\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    tophat = cv2.morphologyEx(b,  \n",
    "                              cv2.MORPH_TOPHAT, \n",
    "                              kernel)\n",
    "    plt.subplot(5, 4, i)\n",
    "    tophathist = cv2.calcHist([tophat],[0],None,[256],[0,256])\n",
    "    plt.plot(tophathist)\n",
    "    plt.title('tophat_on_bilateral')\n",
    "    enh1.append(tophat)\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    plt.imshow(tophat, cmap='gray')\n",
    "    plt.axis('off')  \n",
    "   \n",
    "    if i+1>20:\n",
    "        break\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('images+contrast_enhanced.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks way Better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets compare Edge Detectors - Canny, Sobel and Laplacian \n",
    "plt.figure(figsize=(30,20))\n",
    "i=0\n",
    "filterSize =(50, 30) \n",
    "sob = []\n",
    "can = []\n",
    "lap = []\n",
    "while True:\n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    img = enh1[int(i/4)]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    grad_y = cv2.Sobel(img, cv2.CV_16S, 0, 1, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "    grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    plt.imshow(grad, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Sobel')\n",
    "    sob.append(grad)\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    edge = cv2.Canny(img, 10, 70, apertureSize=3,L2gradient=True )\n",
    "    plt.imshow(edge, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Canny')\n",
    "    can.append(edge)\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(5, 4, i)\n",
    "    dst = cv2.Laplacian(img, cv2.CV_16S, ksize=3)\n",
    "    abs_dst = cv2.convertScaleAbs(dst)\n",
    "    plt.imshow(abs_dst, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Laplacian')\n",
    "    lap.append(abs_dst)\n",
    "        \n",
    "    if i+1>20:\n",
    "        break\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig('edge_detectors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure    \n",
    "entropy = skimage.measure.shannon_entropy(sob[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    print(f'PSNR of Sobel on {j+1}th scan is {PSNR(sob[j],enh1[j]) : 4f}')\n",
    "    print(f'PSNR of Canny on {j+1}th scan is {PSNR(can[j],enh1[j]): 4f}')\n",
    "    print(f'PSNR of Laplacian on {j+1}th scan is {PSNR(lap[j],enh1[j]) : 4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    print(f'MSE of Sobel on {j+1}th scan is {mse(sob[j],enh1[j]) : 4f}')\n",
    "    print(f'MSE of Canny on {j+1}th scan is {mse(can[j],enh1[j]): 4f}')\n",
    "    print(f'MSE of Laplacian on {j+1}th scan is {mse(lap[j],enh1[j]) : 4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    print(f'Entropy of Sobel on {j+1}th scan is {skimage.measure.shannon_entropy(sob[j]) : 4f}')\n",
    "    print(f'Entropy of Canny on {j+1}th scan is {skimage.measure.shannon_entropy(can[j]): 4f}')\n",
    "    print(f'Entropy of Laplacian on {j+1}th scan is {skimage.measure.shannon_entropy(lap[j]) : 4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Application of Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otsu + Binary Thresolding + Skeletonise by erosion\n",
    "\n",
    "trans = []\n",
    "for i in range(5):\n",
    "    imedge=enh1[i]\n",
    "    ret3,th3 = cv2.threshold(imedge,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img = th3\n",
    "    size = np.size(img)\n",
    "    skel = np.zeros(img.shape,np.uint8)\n",
    "\n",
    "    ret,img = cv2.threshold(img,127,255,0)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    done = False\n",
    "\n",
    "    while( not done):\n",
    "        eroded = cv2.erode(img,element)\n",
    "        temp = cv2.dilate(eroded,element)\n",
    "        temp = cv2.subtract(img,temp)\n",
    "        skel = cv2.bitwise_or(skel,temp)\n",
    "        img = eroded.copy()\n",
    "\n",
    "        zeros = size - cv2.countNonZero(img)\n",
    "        if zeros==size:\n",
    "            done = True\n",
    "    dist=skel\n",
    "    # otsu_edge = cv2.Canny(th3, 10, 80, apertureSize=3,L2gradient=True )\n",
    "\n",
    "    # dist = cv2.distanceTransform(th3,cv2.DIST_C,3)\n",
    "    # dist = cv2.normalize(dist, 0, 50.0, cv2.NORM_L2)\n",
    "    # kernel = np.ones((3,3),np.uint8)\n",
    "    # erosion5 = cv2.erode(dist,kernel,iterations = 1)\n",
    "\n",
    "#     cv2.imshow('im0',x[i])\n",
    "    cv2.imshow('image',imedge)\n",
    "    cv2.imshow('Canny + otsu_thresholding',th3)\n",
    "    # cv2.imshow('dist_otsu',dist)\n",
    "    cv2.imshow('Skeletonise',dist)\n",
    "    trans.append(dist)\n",
    "    # cv2.imshow('eroded',erosion5)\n",
    "#     if i==4:\n",
    "#         cv2.imwrite('im_orig.jpg',x[i])\n",
    "#         cv2.imwrite('im_contrast_enhanced.jpg',imedge)\n",
    "#         cv2.imwrite('im_otsu_thresh.jpg',th3)\n",
    "#         # cv2.imshow('dist_otsu',dist)\n",
    "#         cv2.imwrite('im_skeletonize.jpg',dist)\n",
    "\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets trim the background of the scans edges\n",
    "trim = []\n",
    "for i in range(5):\n",
    "    trim.append(trans[i][40:500,int(800/6):int(5*800/6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trim[4],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Matlab code <scan{1-5}.m> files to fit the ellipse on the scans using Iterative Hough Transform. Ensure <ellipseDetection.m> and <ellipse.m> are also in the same folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Hough Transform takes a lot of time to run in python and so MATLAB was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the detected ellipses\n",
    "y = []\n",
    "yt =[]\n",
    "for i in range(5):\n",
    "    yt.append(cv2.imread('./truths/'+str(i)+'.jpg'))\n",
    "    y.append(cv2.imread(str(i)+'.jpg'))\n",
    "truths = []\n",
    "for i in range(5):\n",
    "    truths.append(y[i][40:500,int(800/6):int(5*800/6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('detected',y[0][80:445,100:600])\n",
    "cv2.imshow('truth',yt[0][80:445,100:600])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METRICS\n",
    "def dice(im1, im2):\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    im1 = np.asarray(im1).astype(np.bool)\n",
    "    im2 = np.asarray(im2).astype(np.bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum())\n",
    "\n",
    "import numpy\n",
    "from scipy.ndimage import _ni_support\n",
    "from scipy.ndimage.morphology import distance_transform_edt, binary_erosion,\\\n",
    "    generate_binary_structure\n",
    "from scipy.ndimage.measurements import label, find_objects\n",
    "from scipy.stats import pearsonr\n",
    "def hd95(result, reference, voxelspacing=None, connectivity=1):\n",
    "    \"\"\"\n",
    "    95th percentile of the Hausdorff Distance.\n",
    "\n",
    "    Computes the 95th percentile of the (symmetric) Hausdorff Distance (HD) between the binary objects in two\n",
    "    images. Compared to the Hausdorff Distance, this metric is slightly more stable to small outliers and is\n",
    "    commonly used in Biomedical Segmentation challenges.\n",
    "\n",
    "    \"\"\"\n",
    "    hd1 = __surface_distances(result, reference, voxelspacing, connectivity)\n",
    "    hd2 = __surface_distances(reference, result, voxelspacing, connectivity)\n",
    "    hd95 = numpy.percentile(numpy.hstack((hd1, hd2)), 95)\n",
    "    return hd95\n",
    "def __surface_distances(result, reference, voxelspacing=None, connectivity=1):\n",
    "    \"\"\"\n",
    "    The distances between the surface voxel of binary objects in result and their\n",
    "    nearest partner surface voxel of a binary object in reference.\n",
    "    \"\"\"\n",
    "    result = numpy.atleast_1d(result.astype(numpy.bool))\n",
    "    reference = numpy.atleast_1d(reference.astype(numpy.bool))\n",
    "    if voxelspacing is not None:\n",
    "        voxelspacing = _ni_support._normalize_sequence(voxelspacing, result.ndim)\n",
    "        voxelspacing = numpy.asarray(voxelspacing, dtype=numpy.float64)\n",
    "        if not voxelspacing.flags.contiguous:\n",
    "            voxelspacing = voxelspacing.copy()\n",
    "            \n",
    "    # binary structure\n",
    "    footprint = generate_binary_structure(result.ndim, connectivity)\n",
    "    \n",
    "    # test for emptiness\n",
    "    if 0 == numpy.count_nonzero(result): \n",
    "        raise RuntimeError('The first supplied array does not contain any binary object.')\n",
    "    if 0 == numpy.count_nonzero(reference): \n",
    "        raise RuntimeError('The second supplied array does not contain any binary object.')    \n",
    "            \n",
    "    # extract only 1-pixel border line of objects\n",
    "    result_border = result ^ binary_erosion(result, structure=footprint, iterations=1)\n",
    "    reference_border = reference ^ binary_erosion(reference, structure=footprint, iterations=1)\n",
    "    \n",
    "    # compute average surface distance        \n",
    "    # Note: scipys distance transform is calculated only inside the borders of the\n",
    "    #       foreground objects, therefore the input has to be reversed\n",
    "    dt = distance_transform_edt(~reference_border, sampling=voxelspacing)\n",
    "    sds = dt[result_border]\n",
    "    \n",
    "    return sds\n",
    "def ravd(result, reference):\n",
    "    \"\"\"\n",
    "    Relative absolute surface difference.\n",
    "    \n",
    "    Compute the relative absolute surface difference between the (joined) binary objects\n",
    "    in the two images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result : array_like\n",
    "        Input data containing objects. Can be any type but will be converted\n",
    "        into binary: background where 0, object everywhere else.\n",
    "    reference : array_like\n",
    "        Input data containing objects. Can be any type but will be converted\n",
    "        into binary: background where 0, object everywhere else.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ravd : float\n",
    "        The relative absolute volume difference between the object(s) in ``result``\n",
    "        and the object(s) in ``reference``. This is a percentage value in the range\n",
    "        :math:`[-1.0, +inf]` for which a :math:`0` denotes an ideal score.\n",
    "       \n",
    "    \n",
    "    \"\"\"\n",
    "    result = numpy.atleast_1d(result.astype(numpy.bool))\n",
    "    reference = numpy.atleast_1d(reference.astype(numpy.bool))\n",
    "        \n",
    "    vol1 = numpy.count_nonzero(result)\n",
    "    vol2 = numpy.count_nonzero(reference)\n",
    "    \n",
    "    if 0 == vol2:\n",
    "        raise RuntimeError('The second supplied array does not contain any binary object.')\n",
    "    \n",
    "    return (vol1 - vol2) / float(vol2)\n",
    "def asd(result, reference, voxelspacing=None, connectivity=1):\n",
    "    \"\"\"\n",
    "    Average surface distance metric.\n",
    "    \n",
    "    Computes the average surface distance (ASD) between the binary objects in two images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result : array_like\n",
    "        Input data containing objects. Can be any type but will be converted\n",
    "        into binary: background where 0, object everywhere else.\n",
    "    reference : array_like\n",
    "        Input data containing objects. Can be any type but will be converted\n",
    "        into binary: background where 0, object everywhere else.\n",
    "    voxelspacing : float or sequence of floats, optional\n",
    "        The voxelspacing in a distance unit i.e. spacing of elements\n",
    "        along each dimension. If a sequence, must be of length equal to\n",
    "        the input rank; if a single number, this is used for all axes. If\n",
    "        not specified, a grid spacing of unity is implied.\n",
    "    connectivity : int\n",
    "        The neighbourhood/connectivity considered when determining the surface\n",
    "        of the binary objects. This value is passed to\n",
    "        `scipy.ndimage.morphology.generate_binary_structure` and should usually be :math:`> 1`.\n",
    "        The decision on the connectivity is important, as it can influence the results\n",
    "        strongly. If in doubt, leave it as it is.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    asd : float\n",
    "        The average surface distance between the object(s) in ``result`` and the\n",
    "        object(s) in ``reference``. The distance unit is the same as for the spacing\n",
    "        of elements along each dimension, which is usually given in mm.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    sds = __surface_distances(result, reference, voxelspacing, connectivity)\n",
    "    asd = sds.mean()\n",
    "    return asd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlap of one scan\n",
    "diff = []\n",
    "for i in range(5):\n",
    "    diff.append(cv2.absdiff(y[i],yt[i]))\n",
    "cv2.imshow('OVERLAP',diff[0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize all overlaps\n",
    "s = []\n",
    "st =[]\n",
    "for i in range(5):\n",
    "    st.append(cv2.imread('./truths/'+str(i)+'.jpg'))\n",
    "    s.append(cv2.imread(str(i)+'.jpg'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "i=0\n",
    "filterSize =(30, 20) \n",
    "  \n",
    "while True:\n",
    "    i+=1\n",
    "    plt.subplot(5, 2, i)\n",
    "    img = x[int(i/2)]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "    j=int(i/2)\n",
    "    i+=1\n",
    "    plt.subplot(5, 2, i)\n",
    "    plt.imshow(cv2.absdiff(s[j],st[j]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Overlap')\n",
    "    \n",
    "        \n",
    "    if i+1>10:\n",
    "        break\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('all_overlaps.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dice coefficient\n",
    "dice_metric = []\n",
    "for i in range(5):\n",
    "    dice_metric.append(dice(y[i],yt[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dice_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hausdorff Distance\n",
    "\n",
    "haus_metric = []\n",
    "Y=[]\n",
    "Yt=[]\n",
    "for i in range(5):\n",
    "    Y.append(cv2.cvtColor(y[i],cv2.COLOR_RGB2GRAY))\n",
    "    Yt.append(cv2.cvtColor(yt[i],cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "    haus_metric.append(hd95(Y[i][80:445,100:600], Yt[i][80:445,100:600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative absolute surface difference\n",
    "vdiff_metric = []\n",
    "for i in range(5):\n",
    "    vdiff_metric.append(np.abs(ravd(y[i][80:445,100:600],yt[i][80:445,100:600])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdiff_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average surface difference\n",
    "\n",
    "diff_metric = []\n",
    "for i in range(5):\n",
    "    diff_metric.append((asd(y[i][80:445,100:600],yt[i][80:445,100:600])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_perimeter(a,b):\n",
    "    perimeter = math.pi * ( 3*(a+b) - math.sqrt( (3*a + b) * (a + 3*b) ) )\n",
    "    return perimeter\n",
    "def error_perc(y, y_pred):\n",
    "    return np.absolute(y-y_pred)*100/y\n",
    "\n",
    "circum_in_pixels = []\n",
    "    \n",
    "maj_minor = [ [283.5363,222.4385],[301.6369,258.0478],[254.1441 ,224.1480],[385.7825,370.1430 ],[379.9067 ,303.9660]]\n",
    "\n",
    "circum_truth = np.array([72.09,73.96,78.5,71.9,72.8])\n",
    "pix_to_mm = np.array([0.087755845, 0.085636069, 0.092240975, 0.060673679, 0.065501081])\n",
    "\n",
    "for i in range(5):\n",
    "    circum_in_pixels.append(calculate_perimeter(maj_minor[i][0]/2,maj_minor[i][1]/2))\n",
    "circum_in_pixels = np.asarray(circum_in_pixels)\n",
    "\n",
    "circum_in_mm = pix_to_mm*circum_in_pixels\n",
    "abs_perc = error_perc(circum_truth,circum_in_mm)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Circumference of fetal head of scan {i+1} is {circum_in_mm[i]}%')\n",
    "    print(f'Absolute percetage error in circumference of fetal head of scan {i+1} is {abs_perc[i]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
